{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as tr\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import to_rgba\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train WM model \n",
    "\n",
    "class FFWM(tr.nn.Module):\n",
    "  \"\"\" Model used for Sternberg and N-back \"\"\"\n",
    "  def __init__(self,indim,hiddim,outdim=2,bias=False,add_noise=False):\n",
    "    super().__init__()\n",
    "    self.indim = indim\n",
    "    self.hiddim = hiddim\n",
    "    self.add_noise = add_noise\n",
    "    self.hid1_layer = tr.nn.Linear(indim,indim,bias=bias)\n",
    "    self.hid2_layer = tr.nn.Linear(indim,hiddim,bias=bias)\n",
    "    self.out_layer = tr.nn.Linear(hiddim,outdim,bias=bias)\n",
    "    self.drop2 = tr.nn.Dropout(p=0.05, inplace=False)\n",
    "    bias_dim = indim\n",
    "    max_num_bias_modes = 10\n",
    "    self.embed_bias = tr.nn.Embedding(max_num_bias_modes,bias_dim)\n",
    "    return None\n",
    "\n",
    "  def forward(self,inputL,control_bias_int=0):\n",
    "    \"\"\" inputL is list of tensors \"\"\"\n",
    "    hid1_in = tr.cat(inputL,-1)\n",
    "    hid1_act = self.hid1_layer(hid1_in).relu()\n",
    "    control_bias = self.embed_bias(tr.tensor(control_bias_int))\n",
    "    hid2_in = hid1_act + control_bias\n",
    "    if self.add_noise:\n",
    "      hid2_in = hid2_in + (0.1 ** 0.5) * tr.randn(hid2_in.shape)\n",
    "    hid2_in = self.drop2(hid2_in)\n",
    "    hid2_act = self.hid2_layer(hid2_in).relu()\n",
    "    yhat_t = self.out_layer(hid2_act)\n",
    "    return yhat_t\n",
    "\n",
    "\n",
    "def run_model_for_epochs(net, taskL, ctxt_fn, stim_fn, training, neps_per_task, n_ctxt_steps, verb=True):\n",
    "  if training:\n",
    "    net.train()\n",
    "  else:\n",
    "    net.eval()\n",
    "  lossop = tr.nn.CrossEntropyLoss()\n",
    "  optiop = tr.optim.Adam(net.parameters(), lr=0.001)\n",
    "  score = -np.ones([len(taskL), neps_per_task])\n",
    "  ttype = -np.ones([len(taskL), neps_per_task])\n",
    "  for ep in range(neps_per_task):\n",
    "    if verb and ep % (neps_per_task / 5) == 0:\n",
    "      print(ep / neps_per_task)\n",
    "    # resample stim and context on each ep\n",
    "    stimset = tr.Tensor(stim_fn())\n",
    "    cdrift = ctxt_fn(n_steps=n_ctxt_steps)\n",
    "    cdrift = tr.Tensor(cdrift)\n",
    "    # interleave train on every task per epoch\n",
    "    for task_idx,(control_int,sample_trial_fn,setsize) in enumerate(taskL): \n",
    "      # use the input function to generate a trial sample\n",
    "      out = sample_trial_fn(stimset,cdrift,setsize)\n",
    "      stim_t,stim_m,context_t,context_m,ytarget, ttype_idx = out\n",
    "      # forward prop\n",
    "      inputL = [stim_t,stim_m,context_t,context_m]\n",
    "      yhat = net(inputL,control_bias_int=control_int)\n",
    "      # eval\n",
    "      score[task_idx, ep] = maxsoftmax(yhat)==ytarget\n",
    "      ttype[task_idx, ep] = ttype_idx\n",
    "      # backprop\n",
    "      if training:\n",
    "        eploss = lossop(yhat.unsqueeze(0), ytarget)\n",
    "        optiop.zero_grad()\n",
    "        eploss.backward(retain_graph=True)\n",
    "        optiop.step()\n",
    "  return score, ttype\n",
    "\n",
    "maxsoftmax = lambda x: tr.argmax(tr.softmax(x,-1),-1).squeeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model of CR as spherical coordinates updated by a noisy drift\n",
    "def spherical_drift(n_steps=20, dim=10, var=0.25, mean=0.25):\n",
    "    # initialize the spherical coordinates to ensure each context run begins in a new random location on the unit sphere\n",
    "    ros = np.random.random(dim - 1)\n",
    "    slen = n_steps\n",
    "    ctxt = np.zeros((slen, dim))\n",
    "    for i in range(slen):\n",
    "        noise = np.random.normal(mean, var, size=(dim - 1)) # add a separately-drawn Gaussian to each spherical coord\n",
    "        ros += noise\n",
    "        ctxt[i] = convert_spherical_to_angular(dim, ros)\n",
    "    return ctxt\n",
    "\n",
    "# Convert spherical coordinates to angular ones\n",
    "def convert_spherical_to_angular(dim, ros):\n",
    "    ct = np.zeros(dim)\n",
    "    ct[0] = np.cos(ros[0])\n",
    "    prod = np.product([np.sin(ros[k]) for k in range(1, dim - 1)])\n",
    "    n_prod = prod\n",
    "    for j in range(dim - 2):\n",
    "        n_prod /= np.sin(ros[j + 1])\n",
    "        amt = n_prod * np.cos(ros[j + 1])\n",
    "        ct[j + 1] = amt\n",
    "    ct[dim - 1] = prod\n",
    "    \n",
    "    \n",
    "# Generate identity matrix where each row is a one-hot representation of a stimulus\n",
    "def gen_stims(sdim):\n",
    "    return np.identity(sdim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NBack and Sternberg Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_sternberg_comparison(stimset,cdrift,setsize,\n",
    "  pr_match,pr_stim_lure,pr_context_lure):\n",
    "  # task params\n",
    "  stimset_size,sdim = stimset.shape\n",
    "\n",
    "  # set current stim and context\n",
    "  stim_t_idx = np.random.randint(stimset_size)\n",
    "  stim_t = stimset[stim_t_idx,:]\n",
    "  context_t_idx = setsize * 2 + 1 # the current trace is always the test probe from the second list\n",
    "  context_t = cdrift[context_t_idx]\n",
    "\n",
    "  ## define positive and negative samples\n",
    "  stim_pos = stim_t\n",
    "  context_pos_idx = context_t_idx - np.random.randint(0, setsize)\n",
    "  context_pos = cdrift[context_pos_idx]\n",
    "  # negative context, different trial\n",
    "  context_neg_idx = context_t_idx - np.random.randint(setsize + 1, setsize * 2 + 1)\n",
    "  context_neg = cdrift[context_neg_idx]\n",
    "  # stim\n",
    "  stim_neg_idx = np.random.choice(np.setdiff1d(range(stimset_size), stim_t_idx))\n",
    "  stim_neg = stimset[stim_neg_idx]\n",
    "\n",
    "  # trial type\n",
    "  ttype_randn = np.random.random()\n",
    "\n",
    "  # both match\n",
    "  if ttype_randn<pr_match:\n",
    "    # positive trial\n",
    "    stim_m  = stim_pos\n",
    "    context_m  = context_pos\n",
    "    ytarget = tr.LongTensor([1])\n",
    "    ttype_idx = 0\n",
    "  # slure: stim match (context no match)\n",
    "  elif ttype_randn<pr_match+pr_stim_lure:\n",
    "    # stim lure\n",
    "    stim_m = stim_pos\n",
    "    context_m = context_neg\n",
    "    ytarget = tr.LongTensor([0])\n",
    "    ttype_idx = 2\n",
    "  # clure: context match (stim no match)\n",
    "  elif ttype_randn<pr_match+pr_stim_lure+pr_context_lure:\n",
    "    # context lure\n",
    "    stim_m = stim_neg\n",
    "    context_m = context_pos\n",
    "    ytarget = tr.LongTensor([0])\n",
    "    ttype_idx = 1\n",
    "  # neither match\n",
    "  else:\n",
    "    # negative trial\n",
    "    stim_m = stim_neg\n",
    "    context_m = context_neg\n",
    "    ytarget = tr.LongTensor([0])\n",
    "    ttype_idx = 3\n",
    "  return stim_t,context_t,stim_m,context_m,ytarget,ttype_idx\n",
    "\n",
    "def single_nback_comparison(stimset,cdrift,setsize,\n",
    "  pr_match,pr_stim_lure,pr_context_lure):\n",
    "  \"\"\" \n",
    "  Returns a pair of a stimulus-context traces representing a currently-active stimulus and context & a single trace\n",
    "  retrieved from memory. Generates this pair based on the four comparison types laid out in the paper:\n",
    "    both-match, stim lure, context lure, neither match.\n",
    "  output is a 4-tuple (s_t,c_t,s_r,c_r), as well as ytarget and ttype_code which encodes the trial type for error reporting.\n",
    "  \"\"\"\n",
    "  ntokens,sdim = stimset.shape\n",
    "  min_context_t = setsize\n",
    "\n",
    "  # set current stim and context\n",
    "  stim_t_idx = np.random.randint(0,ntokens)\n",
    "  context_t_idx = np.random.randint(min_context_t, ntokens)\n",
    "  stim_t = stimset[stim_t_idx]\n",
    "  context_t = cdrift[context_t_idx]\n",
    "\n",
    "  ttype_randn = np.random.random()  # randomly-selected trial type\n",
    "  ttype_code = -1 # code used to record trial type for analysis\n",
    "\n",
    "  if ttype_randn < pr_match:\n",
    "    stim_m, context_m = nback_both_match(stimset, cdrift, stim_t_idx, context_t_idx, setsize, ntokens)\n",
    "    ytarget = tr.LongTensor([1])\n",
    "    ttype_code = 0\n",
    "\n",
    "  elif ttype_randn < (pr_match + pr_context_lure):\n",
    "    stim_m, context_m = nback_ctxt_lure(stimset, cdrift, stim_t_idx, context_t_idx, setsize, ntokens)\n",
    "    ytarget = tr.LongTensor([0])\n",
    "    ttype_code = 1\n",
    "\n",
    "  elif ttype_randn < (pr_match + pr_context_lure + pr_stim_lure):\n",
    "    stim_m, context_m = nback_stim_lure(stimset, cdrift, stim_t_idx, context_t_idx, setsize, ntokens)\n",
    "    ytarget = tr.LongTensor([0])\n",
    "    ttype_code = 2\n",
    "\n",
    "  else:\n",
    "    stim_m, context_m = nback_neither_match(stimset, cdrift, stim_t_idx, context_t_idx, setsize, ntokens)\n",
    "    ytarget = tr.LongTensor([0])\n",
    "    ttype_code = 3\n",
    "\n",
    "  return stim_t,stim_m,context_t,context_m,ytarget, ttype_code\n",
    "\n",
    "\n",
    "# return a both match trace -- the stimuli match, and the context is the n-back context\n",
    "def nback_both_match(stim_set, cdrift, stim_t_idx, context_t_idx, setsize, ntokens):\n",
    "    stim_m = stim_set[stim_t_idx]\n",
    "    context_m = cdrift[context_t_idx - setsize]\n",
    "    return (stim_m, context_m)\n",
    "\n",
    "# return a stim lure trace -- the stimuli match, but the context is not the n-back context\n",
    "def nback_stim_lure(stim_set, cdrift, stim_t_idx, context_t_idx, setsize, ntokens):\n",
    "    stim_m = stim_set[stim_t_idx]\n",
    "    context_m = get_lure_context(cdrift, context_t_idx, ntokens, setsize)\n",
    "    return (stim_m, context_m)\n",
    "\n",
    "# return a context lure trace -- the stimuli don't match, but the context is the n-back context\n",
    "def nback_ctxt_lure(stim_set, cdrift, stim_t_idx, context_t_idx, setsize, ntokens):\n",
    "    idx_stim_m = np.random.choice(np.setdiff1d(range(ntokens), stim_t_idx))\n",
    "    stim_m = stim_set[idx_stim_m]\n",
    "    context_m = cdrift[context_t_idx - setsize]\n",
    "    return (stim_m, context_m)\n",
    "\n",
    "# return a neither match trace -- the stimuli don't match, and the context is not the n-back context.\n",
    "# optionally, for the EM simulations, this can probabilistically return a matching stimulus and a long-past context\n",
    "# (s.t. the trace isn't a proper lure, but simulates the repeating-stimuli dynamics of the task).\n",
    "def nback_neither_match(stim_set, cdrift, stim_t_idx, context_t_idx, setsize, ntokens, pr_prewindow_match = 0.0):\n",
    "    if np.random.uniform() > pr_prewindow_match or ntokens - context_t_idx < 6:\n",
    "        idx_stim_m = np.random.choice(np.setdiff1d(range(ntokens), stim_t_idx))\n",
    "        stim_m = stim_set[idx_stim_m]\n",
    "        context_m = get_lure_context(cdrift, context_t_idx, ntokens, setsize)\n",
    "        return stim_m, context_m\n",
    "    else:\n",
    "        return nback_distant_slure(stim_set, cdrift, stim_t_idx, context_t_idx, setsize, ntokens)\n",
    "\n",
    "# A trial type where the stimulus DOES match, but the context is so far from the target context that it isn't a lure\n",
    "def nback_distant_slure(stim_set, cdrift, stim_t_idx, context_t_idx, setsize, ntokens):\n",
    "    idx_stim_m = np.random.choice(np.setdiff1d(range(ntokens), stim_t_idx))\n",
    "    nback_context_idx = context_t_idx + setsize\n",
    "    rlo = max(0, nback_context_idx - 6)\n",
    "    rhi = min(nback_context_idx - 2, ntokens)\n",
    "    idx_context_m = np.random.choice(range(rlo, rhi))\n",
    "    stim_m = stim_set[idx_stim_m]\n",
    "    context_m = cdrift[idx_context_m]\n",
    "    return stim_m, context_m\n",
    "\n",
    "def get_lure_context(cdrift, context_t_idx, ntokens, setsize):\n",
    "    try:\n",
    "        nback_context_idx = context_t_idx - setsize\n",
    "        rlo = max(0, nback_context_idx - 2)\n",
    "        rhi = min(nback_context_idx + setsize, ntokens)\n",
    "        idx_context_m = np.random.choice(np.setdiff1d(range(rlo, rhi), nback_context_idx))\n",
    "        context_m = cdrift[idx_context_m]\n",
    "        return context_m\n",
    "    except:\n",
    "        print(\"Error in generating lure context\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate WM figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training accuracy\n",
    "def plot_train_accuracy(score_tr,\n",
    "                        ttype,\n",
    "                        ssizeL,\n",
    "                        figure_path=\"\"):\n",
    "\n",
    "  task_labels = [\"setsize \" + str(ssize) for ssize in ssizeL]\n",
    "  colors = [[\"#edc174\", \"#d4982f\", \"#c27e08\", \"#a1690a\"], [\"#8dcbf7\", \"#61b3ed\", \"#2a86c7\", \"#0762a3\"]]\n",
    "  labels = [\"match\", \"slure\", \"clure\", \"nomatch\"]\n",
    "  n_intervals = 1000\n",
    "  for i in range(len(score_tr)):\n",
    "    task_score = score_tr[i]\n",
    "    task_color = colors[i]\n",
    "    task_trialtypes = ttype[i]\n",
    "    for tt in range(4):\n",
    "      filt_inds = task_trialtypes == tt\n",
    "      ep_ttype = np.extract(filt_inds, task_score)\n",
    "      ep_ttype = ep_ttype[:-(len(ep_ttype)%n_intervals)]\n",
    "      ac = ep_ttype.reshape(-1, n_intervals).mean(1)\n",
    "      lt = task_labels[i] + \" \" + labels[tt]\n",
    "      plt.plot(ac, color=task_color[tt], label=lt)\n",
    "  plt.legend(loc=\"best\")\n",
    "  plt.ylim(0, 1)\n",
    "  plt.ylabel('Train accuracy')\n",
    "  # plt.savefig(figure_path + \"/train-accuracy\")\n",
    "  # plt.close('all')\n",
    "\n",
    "def eval_by_ttype(net, ctxt_fn, stim_fn, sample_fn, taskintL, ssizeL, n_ctxt_steps, neps):\n",
    "  \"\"\" eval on given task for separate trial types\n",
    "  returns evac on (match,nomatch,slure,clure)\n",
    "  \"\"\"\n",
    "\n",
    "  taskL_ev = []\n",
    "  # generate a list of tasks which are trials all of one kind so we can see accuracy by trial type\n",
    "  for task_int in taskintL:\n",
    "    taskL_ev.append([task_int, sample_fn(1, 0, 0), ssizeL[task_int]])\n",
    "    taskL_ev.append([task_int, sample_fn(0, 0, 0), ssizeL[task_int]])\n",
    "    taskL_ev.append([task_int, sample_fn(0, 1, 0), ssizeL[task_int]])\n",
    "    taskL_ev.append([task_int, sample_fn(0, 0, 1), ssizeL[task_int]])\n",
    "\n",
    "  evsc, ttype = run_model_for_epochs(\n",
    "    net, taskL_ev,\n",
    "    ctxt_fn=ctxt_fn,\n",
    "    stim_fn = stim_fn,\n",
    "    training=False,\n",
    "    neps_per_task=neps,\n",
    "    n_ctxt_steps=n_ctxt_steps,\n",
    "    verb=False\n",
    "  )\n",
    "\n",
    "  evac = evsc.mean(1)\n",
    "  # regroup the scores by the setsize\n",
    "  scores_by_ss = [[]] * len(taskintL)\n",
    "  for task_int in taskintL:\n",
    "    scores_by_ss[task_int] = evac[task_int*4:(task_int+1)*4]\n",
    "  return scores_by_ss\n",
    "\n",
    "# eval on neps_ev iterations of each trial type and plot the accuracy for each\n",
    "def plot_accuracy_by_trial_type(evac,\n",
    "                                taskintL,\n",
    "                                ssizeL,\n",
    "                                figure_path=\"\"):\n",
    "  for tidx, (task_int, ssize) in enumerate(zip(taskintL, ssizeL)):\n",
    "    plt.title('Accuracy by trial type')\n",
    "    plt.bar(np.arange(4) + (.45 * tidx), evac[tidx], width=.45, label=\"setsize:\" + str(ssize))\n",
    "  plt.legend()\n",
    "  plt.xticks(range(4), ['match', 'nomatch', 'slure', 'clure'])\n",
    "  # plt.savefig(figure_path + \"/trial-type-accuracy\")\n",
    "  # plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net_and_plot_accuracy(task, ctxt_fn, stim_fn, c_dim, s_dim, neps, n_ctxt_steps, pr_match, pr_slure, pr_clure, seed, model_path, figure_path):\n",
    "  np.random.seed(seed)\n",
    "  tr.random.manual_seed(seed)\n",
    "\n",
    "  ## net params\n",
    "  indim = 2 * (c_dim + s_dim)\n",
    "  hiddim = s_dim * 4\n",
    "\n",
    "  if task == 'nback':\n",
    "    ssizeL = [2, 3] # [1, 3]\n",
    "    sample_fn = lambda match,slure,clure: lambda S,C,N: single_nback_comparison(S,C,N,\n",
    "                  pr_match=match,pr_stim_lure=slure,pr_context_lure=clure\n",
    "                  )\n",
    "  elif task == 'stern':\n",
    "    ssizeL = [4,9]\n",
    "    sample_fn = lambda match,slure,clure: lambda S,C,N: single_sternberg_comparison(S,C,N,\n",
    "                  pr_match=match,pr_stim_lure=slure,pr_context_lure=clure\n",
    "                  )\n",
    "\n",
    "  taskintL = [0,1]\n",
    "  taskL_tr = [\n",
    "    [taskintL[0],sample_fn(pr_match,pr_slure,pr_clure),ssizeL[0]],\n",
    "    [taskintL[1],sample_fn(pr_match,pr_slure,pr_clure),ssizeL[1]],\n",
    "  ]\n",
    "\n",
    "  # init net\n",
    "  net = FFWM(indim,hiddim)\n",
    "\n",
    "  # train net\n",
    "  score_tr, ttype = run_model_for_epochs(\n",
    "    net,\n",
    "    taskL_tr,\n",
    "    ctxt_fn=ctxt_fn,\n",
    "    stim_fn = stim_fn,\n",
    "    training=True,\n",
    "    neps_per_task=neps,\n",
    "    n_ctxt_steps=n_ctxt_steps)\n",
    "\n",
    "  np.save(model_path + \"/train-score\", score_tr)\n",
    "  tr.save(net.state_dict(), model_path + \"/trained-net.pt\")\n",
    "\n",
    "  plot_train_accuracy(score_tr, ttype, ssizeL, figure_path)\n",
    "\n",
    "  scores_by_ttype = eval_by_ttype(net, ctxt_fn, stim_fn, sample_fn, taskintL, ssizeL, n_ctxt_steps, neps=1000)\n",
    "  plot_accuracy_by_trial_type(scores_by_ttype, taskintL, ssizeL, figure_path)\n",
    "\n",
    "  return net\n",
    "\n",
    "\n",
    "def generate_ttype_figures_for_trained_model(net, task, ctxt_fn, stim_fn, n_ctxt_steps): \n",
    "  if task == 'nback':\n",
    "    ssizeL = [2, 3]\n",
    "    sample_fn = lambda match,slure,clure: lambda S,C,N: single_nback_comparison(S,C,N,\n",
    "                  pr_match=match,pr_stim_lure=slure,pr_context_lure=clure\n",
    "                  )\n",
    "  elif task == 'stern':\n",
    "    ssizeL = [4,9]\n",
    "    sample_fn = lambda match,slure,clure: lambda S,C,N: single_sternberg_comparison(S,C,N,\n",
    "                  pr_match=match,pr_stim_lure=slure,pr_context_lure=clure\n",
    "                  )\n",
    "\n",
    "  taskintL = [0,1]\n",
    "  taskL_tr = [\n",
    "    [taskintL[0],sample_fn(pr_match,pr_slure,pr_clure),ssizeL[0]],\n",
    "    [taskintL[1],sample_fn(pr_match,pr_slure,pr_clure),ssizeL[1]],\n",
    "  ]\n",
    "    \n",
    "  scores_by_ttype = eval_by_ttype(net, ctxt_fn, stim_fn, sample_fn, taskintL, ssizeL, n_ctxt_steps, neps=1000)\n",
    "  plot_accuracy_by_trial_type(scores_by_ttype, taskintL, ssizeL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Parameters & Actually Train / Load a WM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training WM... \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# change this variable to change the task between nback and stern\n",
    "task = \"nback\"  # \"stern\"\n",
    "\n",
    "# function and parameters for the drifting context\n",
    "ctxt_fn_name = spherical_drift\n",
    "drift_parameters = (0.25, 0.075) # [(0.25, 0.075), (0.25, 0.0), (0.25, 0.05), (0.4, 0.075)]\n",
    "ctxt_d = 25\n",
    "n_ctxt_steps=20\n",
    "\n",
    "# function which returns a stimulus - here, always an identity matrix, but could be redrawn from a distribution each time, e.g.\n",
    "stim_d = 20\n",
    "stim_fn = lambda: gen_stims(stim_d) # lambda: gen_stims(stim_d)\n",
    "\n",
    "# probabilities of different training conditions: both match, stimulus lure, context lure, neither match\n",
    "pr_match, pr_slure, pr_clure, pr_nomatch = 0.4, 0.2, 0.2, 0.2\n",
    "\n",
    "# priority weighting of stimulus similarity (vs context similarity) in EM retrieval\n",
    "stim_retrieval_weight = 0.4\n",
    "# hazard rate - likelihood of terminating memory search at each step\n",
    "h_rate = 0.6\n",
    "# similarity threshold cutoff - min cosine similarity before search is terminated deterministically\n",
    "similarity_threshold = 0.5\n",
    "\n",
    "n_training_eps=250000\n",
    "\n",
    "mean, var = drift_parameters\n",
    "\n",
    "# Lambda getter for the context fn with these parameters\n",
    "ctxt_fn = lambda n_steps: spherical_drift(n_steps=n_steps, dim=ctxt_d, var=var, mean=mean)\n",
    "\n",
    "print(\"Training WM... \")\n",
    "\n",
    "load_pretrained_model = True\n",
    "\n",
    "if load_pretrained_model: \n",
    "    model_path = \"/Users/maia/Projects/cleaned-em-wm-code/trained-models/ffwm_task-nback_training-probs-040-020-020-020_neps-500000_drift-params-025-007_seed%1/trained-net.pt\"\n",
    "    model = FFWM(2 * (ctxt_d + stim_d), stim_d * 4)\n",
    "    model.load_state_dict(tr.load(model_path))\n",
    "    model.eval()\n",
    "    generate_ttype_figures_for_trained_model(model, task, ctxt_fn, stim_fn, n_ctxt_steps=n_ctxt_steps)\n",
    "else: \n",
    "    net = train_net_and_plot_accuracy(task, ctxt_fn, stim_fn, c_dim=ctxt_d, s_dim=stim_d, neps=n_training_eps, n_ctxt_steps=n_ctxt_steps,\n",
    "                                    pr_match=pr_match, pr_slure=pr_slure, pr_clure=pr_clure, seed=seed,\n",
    "                                    model_path=model_path, figure_path=figure_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cosine similarity between two vectors\n",
    "def cos_sim(a, b):\n",
    "    return cosine_similarity(a.reshape(1, -1), b.reshape(1, -1))\n",
    "\n",
    "def sample_nback_retrieval_set_for_trial_sequence(stimset, cdrift, setsize,\n",
    "                                          pr_match, pr_stim_lure, pr_context_lure):\n",
    "    \"\"\"\n",
    "    Simulates the set of traces in EM corresponding to a possible n-back sequence for a particular trial type,\n",
    "    returning an list of tuples (with the current trial is at index 0)\n",
    "    of stimulus and context information, as well as the true answer ytarget and a code for the trial type.\n",
    "    \"\"\"\n",
    "    n_traces = 10\n",
    "    trace_seq = [None] * n_traces\n",
    "    ntokens,sdim = stimset.shape\n",
    "    min_context_t = setsize\n",
    "\n",
    "    ## current stim and context\n",
    "    stim_t_idx = np.random.randint(0,ntokens)\n",
    "    context_t_idx = np.random.randint(min_context_t, ntokens)\n",
    "    stim_t = stimset[stim_t_idx]\n",
    "    context_t = cdrift[context_t_idx]\n",
    "    trace_seq[0] = (stim_t, context_t) # the 0th index is the current stim, context\n",
    "\n",
    "    ttype_rand_n = np.random.random() # random number for determining the trial type\n",
    "    ttype_code = -1  # code for the trial type that will be returned - 0 if a control, and 1 if a lure\n",
    "\n",
    "    # control target\n",
    "    if ttype_rand_n < pr_match:\n",
    "        # One trace in the n-back position with a matching stimulus\n",
    "        trace_seq[setsize] = nback_both_match(stimset, cdrift, stim_t_idx, context_t_idx, setsize, ntokens)\n",
    "        # All other traces in the sequence are from non-nback positions and have non-matching stimuli\n",
    "        for i in range(1, n_traces):\n",
    "          if i != setsize:\n",
    "              trace_seq[i] = nback_neither_match(stimset, cdrift, stim_t_idx, context_t_idx, setsize, ntokens)\n",
    "        ytarget = tr.LongTensor([1])\n",
    "        ttype_code = 0\n",
    "\n",
    "    # control foil\n",
    "    elif ttype_rand_n < (pr_match + pr_context_lure):\n",
    "        # One trace in the n-back position with a non-matching stimulus\n",
    "        trace_seq[setsize] = nback_ctxt_lure(stimset, cdrift, stim_t_idx, context_t_idx, setsize, ntokens)\n",
    "        # All other traces in the sequence have non-matching stimuli\n",
    "        for i in range(1, n_traces):\n",
    "            if i != setsize:\n",
    "                trace_seq[i] = nback_neither_match(stimset, cdrift, stim_t_idx, context_t_idx, setsize, ntokens)\n",
    "        ytarget = tr.LongTensor([0])\n",
    "        ttype_code = 0\n",
    "\n",
    "    # lure target\n",
    "    elif ttype_rand_n < (pr_match + pr_context_lure + pr_stim_lure):\n",
    "        # One trace in the n-back position with a matching stimulus\n",
    "        trace_seq[setsize] = nback_both_match(stimset, cdrift, stim_t_idx, context_t_idx, setsize, ntokens)\n",
    "        # One trace in the non n-back position has a non-matching stimulus\n",
    "        trace_seq[setsize - 1] = nback_stim_lure(stimset, cdrift, stim_t_idx, context_t_idx, setsize, ntokens)\n",
    "        # All other traces have non-matching stimuli\n",
    "        for i in range(1, n_traces):\n",
    "            if i != setsize and i != setsize - 1:\n",
    "                trace_seq[i] = nback_neither_match(stimset, cdrift, stim_t_idx, context_t_idx, setsize, ntokens)\n",
    "        ytarget = tr.LongTensor([1])\n",
    "        ttype_code = 1\n",
    "\n",
    "    # lure foil\n",
    "    else:\n",
    "      # The trace in the n-back position has a non-matching stimulus\n",
    "      trace_seq[1] = nback_ctxt_lure(stimset, cdrift, stim_t_idx, context_t_idx, setsize, ntokens)\n",
    "      # The trace one-after the n-back position (the lure position) has a matching stimulus\n",
    "      trace_seq[2] = nback_stim_lure(stimset, cdrift, stim_t_idx, context_t_idx, setsize, ntokens)\n",
    "      # All other traces in the sequence other than the n-back position have non-matching stimuli\n",
    "      for i in range(3, n_traces):\n",
    "        trace_seq[i] = nback_neither_match(stimset, cdrift, stim_t_idx, context_t_idx, setsize, ntokens)\n",
    "      ytarget = tr.LongTensor([0])\n",
    "      ttype_code = 1\n",
    "\n",
    "    return trace_seq, ytarget, ttype_code\n",
    "\n",
    "def get_em_model_performance(net, taskL, ctxt_fn, stim_fn, neps_per_task, n_context_steps, stim_priority_weight, hrate, sim_thresh):\n",
    "    \"\"\"\n",
    "    Train the model on a particular task, taking measures both of its cross-category training performance and of\n",
    "    its d' characteristics\n",
    "    \"\"\"\n",
    "    net.eval()\n",
    "    score = -np.ones([len(taskL), neps_per_task, 2]) # array of performance information\n",
    "    ttype = -np.ones([len(taskL), neps_per_task]) # array of trial-type information for d' measures\n",
    "    for ep in range(neps_per_task):\n",
    "        # resample context for this epoch\n",
    "        stimset = tr.Tensor(stim_fn())\n",
    "        cdrift = ctxt_fn(n_steps=n_context_steps)\n",
    "        cdrift = tr.Tensor(cdrift)\n",
    "        # interleave training for multiple task conditions each epoch\n",
    "        for task_idx,(control_int,sample_trial_fn,setsize) in enumerate(taskL):\n",
    "          # generate sample trace set\n",
    "          stimseq,ytarget, ttype_idx = sample_trial_fn(stimset,cdrift,setsize)\n",
    "          target = stimseq[0]\n",
    "          sim_scores = []\n",
    "          for memory in stimseq[1:]:\n",
    "              # calculate a trace's retrieval priority based on weighted cosine similarity between the trace and the current trace\n",
    "              cs_stim = cos_sim(target[0], memory[0])\n",
    "              cs_ctxt = cos_sim(target[1], memory[1])\n",
    "              sim = stim_priority_weight * cs_stim + (1 - stim_priority_weight) * cs_ctxt # weighting parameter\n",
    "              sim_scores.append(sim)\n",
    "          pred = 0\n",
    "          # repeat as long as there are traces in the retrieval set\n",
    "          for i in range(len(sim_scores)):\n",
    "              max_sim_idx = np.argmax(np.array(sim_scores)) # pick the remaining trace with the highest similarity\n",
    "              if (sim_scores[max_sim_idx] < sim_thresh):\n",
    "                  break # break if the most-similar trace is under the threshold\n",
    "              memory = stimseq[max_sim_idx + 1]\n",
    "              inputL = [target[0],memory[0],target[1],memory[1]]\n",
    "              yhat = net(inputL,control_bias_int=control_int)\n",
    "              # predict a label for the trace\n",
    "              pred = maxsoftmax(yhat).item()\n",
    "              if pred == 1: # stop search if the model identifies a trace that evidences a positive trial\n",
    "                  break\n",
    "              if np.random.uniform() > (hrate): # stop search with probability hrate\n",
    "                  break\n",
    "              else:\n",
    "                  sim_scores[max_sim_idx] = 0 # else zero out the retrieval priority of this trace\n",
    "          score[task_idx, ep, 0] = pred\n",
    "          score[task_idx, ep, 1] = ytarget.item()\n",
    "          ttype[task_idx, ep] = ttype_idx\n",
    "    return score, ttype\n",
    "\n",
    "def simulate_em_and_plot_dprimes(net, ctxt_fn, stim_fn, neps_per_task, pr_match, pr_slure, pr_clure, n_context_steps, stim_priority_weight, hrate, sim_thresh, figure_path=\"\"):\n",
    "    ssizeL = [2, 3]\n",
    "    sample_fn = lambda match, slure, clure: lambda S, C, N: sample_nback_retrieval_set_for_trial_sequence(S, C, N,\n",
    "                                                                                    pr_match=match,\n",
    "                                                                                    pr_stim_lure=slure,\n",
    "                                                                                    pr_context_lure=clure\n",
    "                                                                                    )\n",
    "    taskintL = [0, 1]\n",
    "    taskL = [\n",
    "        [taskintL[0], sample_fn(pr_match, pr_slure, pr_clure), ssizeL[0]],\n",
    "        [taskintL[1], sample_fn(pr_match, pr_slure, pr_clure), ssizeL[1]],\n",
    "    ]\n",
    "\n",
    "    score, ttype = get_em_model_performance(net, taskL, ctxt_fn, stim_fn, neps_per_task, n_context_steps,\n",
    "                                            stim_priority_weight, hrate, sim_thresh)\n",
    "\n",
    "    dprime_fig_path = figure_path + (\"/dprime\" + '_sw=' + str(stim_priority_weight) + \"_hrate=\" + str(hrate)).replace(\".\", \"\")\n",
    "\n",
    "    calculate_and_plot_dprime(score, ttype, dprime_figure_path=dprime_fig_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot d' Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates Kane d' measures for a set of results and graphs them\n",
    "def calculate_and_plot_dprime(evsc, ttype, dprime_figure_path):\n",
    "    taskL = [0, 1]\n",
    "    rate_sum = np.zeros([len(taskL), 2, 4])\n",
    "\n",
    "    dprimes = [None] * 4\n",
    "    bias = [None] * 4\n",
    "    hits = [None] * 4\n",
    "    correct_rejections = [None] * 4\n",
    "    labels = [\"2-back ctrl\", \"2-back lure\", \"3-back ctrl\", \"3-back lure\"]\n",
    "\n",
    "    idx = 0\n",
    "\n",
    "    for task in taskL:\n",
    "        task_score = evsc[task]\n",
    "        for i in range(len(task_score)):\n",
    "            ep = task_score[i]\n",
    "            ttype_idx = int(ttype[task, i])\n",
    "            if ep[0] == 1 and ep[1] == 1:\n",
    "                rate_sum[task, ttype_idx, 0] += 1\n",
    "            elif ep[0] == 1 and ep[1] == 0:\n",
    "                rate_sum[task, ttype_idx, 1] += 1\n",
    "            elif ep[0] == 0 and ep[1] == 1:\n",
    "                rate_sum[task, ttype_idx, 2] += 1\n",
    "            elif ep[0] == 0 and ep[1] == 0:\n",
    "                rate_sum[task, ttype_idx, 3] += 1\n",
    "            else:\n",
    "                raise ValueError(\"unexpected set of values: \" + str(ep))\n",
    "        for ttype_idx in [0, 1]:\n",
    "            n_ytrials = rate_sum[task, ttype_idx, 0] + rate_sum[task, ttype_idx, 2]\n",
    "            n_ntrials = rate_sum[task, ttype_idx, 1] + rate_sum[task, ttype_idx, 3]\n",
    "            rate_sum[task, ttype_idx, 0] = rate_sum[task, ttype_idx, 0] / n_ytrials\n",
    "            rate_sum[task, ttype_idx, 1] = rate_sum[task, ttype_idx, 1] / n_ntrials\n",
    "            rate_sum[task, ttype_idx, 2] = rate_sum[task, ttype_idx, 2] / n_ytrials\n",
    "            rate_sum[task, ttype_idx, 3] = rate_sum[task, ttype_idx, 3] / n_ntrials\n",
    "            dprime, sensitivity = paper_dprime(rate_sum[task, ttype_idx][0], rate_sum[task, ttype_idx][1])\n",
    "            dprimes[idx] = dprime\n",
    "            bias[idx] = sensitivity\n",
    "            hits[idx] = rate_sum[task, ttype_idx, 0]\n",
    "            correct_rejections[idx] = rate_sum[task, ttype_idx, 3]\n",
    "            idx += 1\n",
    "\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(10, 15))\n",
    "    width = 0.9\n",
    "\n",
    "    fig.suptitle(\"d-prime measures of retrieval model performance\", fontsize=20)\n",
    "\n",
    "    titles = [\"correct rejections\", \"hits\", \"sensitivity\", \"bias\"]\n",
    "    stats = [correct_rejections, hits, dprimes, bias]\n",
    "    colors = [\"C0\", to_rgba(\"C0\", 0.7), \"C1\", to_rgba(\"C1\", 0.7)]\n",
    "\n",
    "    for i in range(4):\n",
    "        ax = axs[int(i / 2), i%2]\n",
    "        for j in range(4):\n",
    "            ax.bar(j, stats[i][j], width, label=labels[j], color=colors[j])\n",
    "        ax.tick_params(axis='x', which=\"both\", bottom=False)\n",
    "        ax.set_title(titles[i], y=-0.12)\n",
    "        if i < 2:\n",
    "            ax.set_ylim(0, 1.1)\n",
    "        else:\n",
    "            ax.set_ylim(-5, 10)\n",
    "            ax.axhline(0, color=\"black\")\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(\"Correct Rejection / Hit Rate\")\n",
    "        if i == 2:\n",
    "            ax.set_ylabel(\"Signal Detection Measures\")\n",
    "        if i == 3:\n",
    "            ax.legend()\n",
    "\n",
    "    # plt.savefig(dprime_figure_path)\n",
    "    # plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the model to generate EM figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating EM...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-e605d44e2a45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                \u001b[0mhrate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                \u001b[0msim_thresh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilarity_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                               figure_path=\"\")\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-fa3281aa655a>\u001b[0m in \u001b[0;36msimulate_em_and_plot_dprimes\u001b[0;34m(net, ctxt_fn, stim_fn, neps_per_task, pr_match, pr_slure, pr_clure, n_context_steps, stim_priority_weight, hrate, sim_thresh, figure_path)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     score, ttype = get_em_model_performance(net, taskL, ctxt_fn, stim_fn, neps_per_task, n_context_steps,\n\u001b[0;32m--> 137\u001b[0;31m                                             stim_priority_weight, hrate, sim_thresh)\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mdprime_fig_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfigure_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"/dprime\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_sw='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstim_priority_weight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_hrate=\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-fa3281aa655a>\u001b[0m in \u001b[0;36mget_em_model_performance\u001b[0;34m(net, taskL, ctxt_fn, stim_fn, neps_per_task, n_context_steps, stim_priority_weight, hrate, sim_thresh)\u001b[0m\n\u001b[1;32m     96\u001b[0m               \u001b[0;31m# calculate a trace's retrieval priority based on weighted cosine similarity between the trace and the current trace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m               \u001b[0mcs_stim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcos_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m               \u001b[0mcs_ctxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcos_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m               \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstim_priority_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcs_stim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstim_priority_weight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcs_ctxt\u001b[0m \u001b[0;31m# weighting parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m               \u001b[0msim_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-fa3281aa655a>\u001b[0m in \u001b[0;36mcos_sim\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Calculate the cosine similarity between two vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcos_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m def sample_nback_retrieval_set_for_trial_sequence(stimset, cdrift, setsize,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1025\u001b[0m     \u001b[0;31m# to avoid recursive import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         X = check_array(X, accept_sparse='csr', dtype=dtype,\n\u001b[0;32m--> 112\u001b[0;31m                         estimator=estimator)\n\u001b[0m\u001b[1;32m    113\u001b[0m         Y = check_array(Y, accept_sparse='csr', dtype=dtype,\n\u001b[1;32m    114\u001b[0m                         estimator=estimator)\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 542\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "if task == \"nback\":\n",
    "  print(\"Simulating EM...\")\n",
    "  simulate_em_and_plot_dprimes(model, ctxt_fn, stim_fn,\n",
    "                               neps_per_task=5000, pr_match=pr_match,\n",
    "                                pr_slure=pr_slure, pr_clure=pr_clure, n_context_steps=n_ctxt_steps,\n",
    "                               stim_priority_weight=stim_retrieval_weight,\n",
    "                               hrate = h_rate,\n",
    "                               sim_thresh = similarity_threshold,\n",
    "                              figure_path=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
