{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as tr\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import to_rgba\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train WM model \n",
    "\n",
    "class FFWM(tr.nn.Module):\n",
    "  \"\"\" Model used for Sternberg and N-back \"\"\"\n",
    "  def __init__(self,indim,hiddim,outdim=2,bias=False,add_noise=False):\n",
    "    super().__init__()\n",
    "    self.indim = indim\n",
    "    self.hiddim = hiddim\n",
    "    self.add_noise = add_noise\n",
    "    self.hid1_layer = tr.nn.Linear(indim,indim,bias=bias)\n",
    "    self.hid2_layer = tr.nn.Linear(indim,hiddim,bias=bias)\n",
    "    self.out_layer = tr.nn.Linear(hiddim,outdim,bias=bias)\n",
    "    self.drop2 = tr.nn.Dropout(p=0.05, inplace=False)\n",
    "    bias_dim = indim\n",
    "    max_num_bias_modes = 10\n",
    "    self.embed_bias = tr.nn.Embedding(max_num_bias_modes,bias_dim)\n",
    "    return None\n",
    "\n",
    "  def forward(self,inputL,control_bias_int=0):\n",
    "    \"\"\" inputL is list of tensors \"\"\"\n",
    "    hid1_in = tr.cat(inputL,-1)\n",
    "    hid1_act = self.hid1_layer(hid1_in).relu()\n",
    "    control_bias = self.embed_bias(tr.tensor(control_bias_int))\n",
    "    hid2_in = hid1_act + control_bias\n",
    "    if self.add_noise:\n",
    "      hid2_in = hid2_in + (0.1 ** 0.5) * tr.randn(hid2_in.shape)\n",
    "    hid2_in = self.drop2(hid2_in)\n",
    "    hid2_act = self.hid2_layer(hid2_in).relu()\n",
    "    yhat_t = self.out_layer(hid2_act)\n",
    "    return yhat_t\n",
    "\n",
    "\n",
    "def run_model_for_epochs(net, taskL, ctxt_fn, stim_fn, training, neps_per_task, n_ctxt_steps, verb=True):\n",
    "  if training:\n",
    "    net.train()\n",
    "    print(\"Training WM...\")\n",
    "  else:\n",
    "    net.eval()\n",
    "    print(\"Evaluating WM...\")\n",
    "  lossop = tr.nn.CrossEntropyLoss()\n",
    "  optiop = tr.optim.Adam(net.parameters(), lr=0.001)\n",
    "  score = -np.ones([len(taskL), neps_per_task])\n",
    "  ttype = -np.ones([len(taskL), neps_per_task])\n",
    "  for ep in range(neps_per_task):\n",
    "    if verb and ep % (neps_per_task / 5) == 0:\n",
    "      print(ep / neps_per_task)\n",
    "    # resample stim and context on each ep\n",
    "    stimset = tr.Tensor(stim_fn())\n",
    "    cdrift = ctxt_fn(n_steps=n_ctxt_steps)\n",
    "    cdrift = tr.Tensor(cdrift)\n",
    "    # interleave train on every task per epoch\n",
    "    for task_idx,(control_int,sample_trial_fn,setsize) in enumerate(taskL): \n",
    "      # use the input function to generate a trial sample\n",
    "      out = sample_trial_fn(stimset,cdrift,setsize)\n",
    "      stim_t,stim_m,context_t,context_m,ytarget, ttype_idx = out\n",
    "      # forward prop\n",
    "      inputL = [stim_t,stim_m,context_t,context_m]\n",
    "      yhat = net(inputL,control_bias_int=control_int)\n",
    "      # eval\n",
    "      score[task_idx, ep] = maxsoftmax(yhat)==ytarget\n",
    "      ttype[task_idx, ep] = ttype_idx\n",
    "      # backprop\n",
    "      if training:\n",
    "        eploss = lossop(yhat.unsqueeze(0), ytarget)\n",
    "        optiop.zero_grad()\n",
    "        eploss.backward(retain_graph=True)\n",
    "        optiop.step()\n",
    "  return score, ttype\n",
    "\n",
    "maxsoftmax = lambda x: tr.argmax(tr.softmax(x,-1),-1).squeeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model of CR as spherical coordinates updated by a noisy drift\n",
    "def spherical_drift(n_steps=20, dim=10, var=0.25, mean=0.25):\n",
    "    # initialize the spherical coordinates to ensure each context run begins in a new random location on the unit sphere\n",
    "    ros = np.random.random(dim - 1)\n",
    "    slen = n_steps\n",
    "    ctxt = np.zeros((slen, dim))\n",
    "    for i in range(slen):\n",
    "        noise = np.random.normal(mean, var, size=(dim - 1)) # add a separately-drawn Gaussian to each spherical coord\n",
    "        ros += noise\n",
    "        ctxt[i] = convert_spherical_to_angular(dim, ros)\n",
    "    return ctxt\n",
    "\n",
    "# Convert spherical coordinates to angular ones\n",
    "def convert_spherical_to_angular(dim, ros):\n",
    "    ct = np.zeros(dim)\n",
    "    ct[0] = np.cos(ros[0])\n",
    "    prod = np.product([np.sin(ros[k]) for k in range(1, dim - 1)])\n",
    "    n_prod = prod\n",
    "    for j in range(dim - 2):\n",
    "        n_prod /= np.sin(ros[j + 1])\n",
    "        amt = n_prod * np.cos(ros[j + 1])\n",
    "        ct[j + 1] = amt\n",
    "    ct[dim - 1] = prod\n",
    "    return ct\n",
    "    \n",
    "    \n",
    "# Generate identity matrix where each row is a one-hot representation of a stimulus\n",
    "def gen_stims(sdim):\n",
    "    return np.identity(sdim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NBack and Sternberg Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_sternberg_comparison(stimset,cdrift,setsize,\n",
    "  pr_match,pr_stim_lure,pr_context_lure):\n",
    "  # task params\n",
    "  stimset_size,sdim = stimset.shape\n",
    "\n",
    "  # set current stim and context\n",
    "  stim_t_idx = np.random.randint(stimset_size)\n",
    "  stim_t = stimset[stim_t_idx,:]\n",
    "  context_t_idx = setsize * 2 + 1 # the current trace is always the test probe from the second list\n",
    "  context_t = cdrift[context_t_idx]\n",
    "\n",
    "  ## define positive and negative samples\n",
    "  stim_pos = stim_t\n",
    "  context_pos_idx = context_t_idx - np.random.randint(0, setsize)\n",
    "  context_pos = cdrift[context_pos_idx]\n",
    "  # negative context, different trial\n",
    "  context_neg_idx = context_t_idx - np.random.randint(setsize + 1, setsize * 2 + 1)\n",
    "  context_neg = cdrift[context_neg_idx]\n",
    "  # stim\n",
    "  stim_neg_idx = np.random.choice(np.setdiff1d(range(stimset_size), stim_t_idx))\n",
    "  stim_neg = stimset[stim_neg_idx]\n",
    "\n",
    "  # trial type\n",
    "  ttype_randn = np.random.random()\n",
    "\n",
    "  # both match\n",
    "  if ttype_randn<pr_match:\n",
    "    # positive trial\n",
    "    stim_m  = stim_pos\n",
    "    context_m  = context_pos\n",
    "    ytarget = tr.LongTensor([1])\n",
    "    ttype_idx = 0\n",
    "  # slure: stim match (context no match)\n",
    "  elif ttype_randn<pr_match+pr_stim_lure:\n",
    "    # stim lure\n",
    "    stim_m = stim_pos\n",
    "    context_m = context_neg\n",
    "    ytarget = tr.LongTensor([0])\n",
    "    ttype_idx = 2\n",
    "  # clure: context match (stim no match)\n",
    "  elif ttype_randn<pr_match+pr_stim_lure+pr_context_lure:\n",
    "    # context lure\n",
    "    stim_m = stim_neg\n",
    "    context_m = context_pos\n",
    "    ytarget = tr.LongTensor([0])\n",
    "    ttype_idx = 1\n",
    "  # neither match\n",
    "  else:\n",
    "    # negative trial\n",
    "    stim_m = stim_neg\n",
    "    context_m = context_neg\n",
    "    ytarget = tr.LongTensor([0])\n",
    "    ttype_idx = 3\n",
    "  return stim_t,context_t,stim_m,context_m,ytarget,ttype_idx\n",
    "\n",
    "def single_nback_comparison(stimset,cdrift,setsize,\n",
    "  pr_match,pr_stim_lure,pr_context_lure):\n",
    "  \"\"\" \n",
    "  Returns a pair of a stimulus-context traces representing a currently-active stimulus and context & a single trace\n",
    "  retrieved from memory. Generates this pair based on the four comparison types laid out in the paper:\n",
    "    both-match, stim lure, context lure, neither match.\n",
    "  output is a 4-tuple (s_t,c_t,s_r,c_r), as well as ytarget and ttype_code which encodes the trial type for error reporting.\n",
    "  \"\"\"\n",
    "  ntokens,sdim = stimset.shape\n",
    "  min_context_t = setsize\n",
    "\n",
    "  # set current stim and context\n",
    "  stim_t_idx = np.random.randint(0,ntokens)\n",
    "  context_t_idx = np.random.randint(min_context_t, ntokens)\n",
    "  stim_t = stimset[stim_t_idx]\n",
    "  context_t = cdrift[context_t_idx]\n",
    "\n",
    "  ttype_randn = np.random.random()  # randomly-selected trial type\n",
    "  ttype_code = -1 # code used to record trial type for analysis\n",
    "\n",
    "  if ttype_randn < pr_match:\n",
    "    stim_m, context_m = nback_both_match(stimset, cdrift, stim_t_idx, context_t_idx, setsize, ntokens)\n",
    "    ytarget = tr.LongTensor([1])\n",
    "    ttype_code = 0\n",
    "\n",
    "  elif ttype_randn < (pr_match + pr_context_lure):\n",
    "    stim_m, context_m = nback_ctxt_lure(stimset, cdrift, stim_t_idx, context_t_idx, setsize, ntokens)\n",
    "    ytarget = tr.LongTensor([0])\n",
    "    ttype_code = 1\n",
    "\n",
    "  elif ttype_randn < (pr_match + pr_context_lure + pr_stim_lure):\n",
    "    stim_m, context_m = nback_stim_lure(stimset, cdrift, stim_t_idx, context_t_idx, setsize, ntokens)\n",
    "    ytarget = tr.LongTensor([0])\n",
    "    ttype_code = 2\n",
    "\n",
    "  else:\n",
    "    stim_m, context_m = nback_neither_match(stimset, cdrift, stim_t_idx, context_t_idx, setsize, ntokens)\n",
    "    ytarget = tr.LongTensor([0])\n",
    "    ttype_code = 3\n",
    "\n",
    "  return stim_t,stim_m,context_t,context_m,ytarget, ttype_code\n",
    "\n",
    "\n",
    "# return a both match trace -- the stimuli match, and the context is the n-back context\n",
    "def nback_both_match(stim_set, cdrift, stim_t_idx, context_t_idx, setsize, ntokens):\n",
    "    stim_m = stim_set[stim_t_idx]\n",
    "    context_m = cdrift[context_t_idx - setsize]\n",
    "    return (stim_m, context_m)\n",
    "\n",
    "# return a stim lure trace -- the stimuli match, but the context is not the n-back context\n",
    "def nback_stim_lure(stim_set, cdrift, stim_t_idx, context_t_idx, setsize, ntokens):\n",
    "    stim_m = stim_set[stim_t_idx]\n",
    "    context_m = get_lure_context(cdrift, context_t_idx, ntokens, setsize)\n",
    "    return (stim_m, context_m)\n",
    "\n",
    "# return a context lure trace -- the stimuli don't match, but the context is the n-back context\n",
    "def nback_ctxt_lure(stim_set, cdrift, stim_t_idx, context_t_idx, setsize, ntokens):\n",
    "    idx_stim_m = np.random.choice(np.setdiff1d(range(ntokens), stim_t_idx))\n",
    "    stim_m = stim_set[idx_stim_m]\n",
    "    context_m = cdrift[context_t_idx - setsize]\n",
    "    return (stim_m, context_m)\n",
    "\n",
    "# return a neither match trace -- the stimuli don't match, and the context is not the n-back context.\n",
    "# optionally, for the EM simulations, this can probabilistically return a matching stimulus and a long-past context\n",
    "# (s.t. the trace isn't a proper lure, but simulates the repeating-stimuli dynamics of the task).\n",
    "def nback_neither_match(stim_set, cdrift, stim_t_idx, context_t_idx, setsize, ntokens, pr_prewindow_match = 0.0):\n",
    "    if np.random.uniform() > pr_prewindow_match or ntokens - context_t_idx < 6:\n",
    "        idx_stim_m = np.random.choice(np.setdiff1d(range(ntokens), stim_t_idx))\n",
    "        stim_m = stim_set[idx_stim_m]\n",
    "        context_m = get_lure_context(cdrift, context_t_idx, ntokens, setsize)\n",
    "        return stim_m, context_m\n",
    "    else:\n",
    "        return nback_distant_slure(stim_set, cdrift, stim_t_idx, context_t_idx, setsize, ntokens)\n",
    "\n",
    "# A trial type where the stimulus DOES match, but the context is so far from the target context that it isn't a lure\n",
    "def nback_distant_slure(stim_set, cdrift, stim_t_idx, context_t_idx, setsize, ntokens):\n",
    "    idx_stim_m = np.random.choice(np.setdiff1d(range(ntokens), stim_t_idx))\n",
    "    nback_context_idx = context_t_idx + setsize\n",
    "    rlo = max(0, nback_context_idx - 6)\n",
    "    rhi = min(nback_context_idx - 2, ntokens)\n",
    "    idx_context_m = np.random.choice(range(rlo, rhi))\n",
    "    stim_m = stim_set[idx_stim_m]\n",
    "    context_m = cdrift[idx_context_m]\n",
    "    return stim_m, context_m\n",
    "\n",
    "def get_lure_context(cdrift, context_t_idx, ntokens, setsize):\n",
    "    try:\n",
    "        nback_context_idx = context_t_idx - setsize\n",
    "        rlo = max(0, nback_context_idx - 2)\n",
    "        rhi = min(nback_context_idx + setsize, ntokens)\n",
    "        idx_context_m = np.random.choice(np.setdiff1d(range(rlo, rhi), nback_context_idx))\n",
    "        context_m = cdrift[idx_context_m]\n",
    "        return context_m\n",
    "    except:\n",
    "        print(\"Error in generating lure context\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate WM figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training accuracy\n",
    "def plot_train_accuracy(score_tr,\n",
    "                        ttype,\n",
    "                        ssizeL,\n",
    "                        figure_path=\"\"):\n",
    "\n",
    "  task_labels = [\"setsize \" + str(ssize) for ssize in ssizeL]\n",
    "  colors = [[\"#edc174\", \"#d4982f\", \"#c27e08\", \"#a1690a\"], [\"#8dcbf7\", \"#61b3ed\", \"#2a86c7\", \"#0762a3\"]]\n",
    "  labels = [\"match\", \"slure\", \"clure\", \"nomatch\"]\n",
    "  n_intervals = 1000\n",
    "  for i in range(len(score_tr)):\n",
    "    task_score = score_tr[i]\n",
    "    task_color = colors[i]\n",
    "    task_trialtypes = ttype[i]\n",
    "    for tt in range(4):\n",
    "      filt_inds = task_trialtypes == tt\n",
    "      ep_ttype = np.extract(filt_inds, task_score)\n",
    "      ep_ttype = ep_ttype[:-(len(ep_ttype)%n_intervals)]\n",
    "      ac = ep_ttype.reshape(-1, n_intervals).mean(1)\n",
    "      lt = task_labels[i] + \" \" + labels[tt]\n",
    "      plt.plot(ac, color=task_color[tt], label=lt)\n",
    "  plt.legend(loc=\"best\")\n",
    "  plt.ylim(0, 1)\n",
    "  plt.ylabel('Train accuracy')\n",
    "  # plt.savefig(figure_path + \"/train-accuracy\")\n",
    "  # plt.close('all')\n",
    "\n",
    "def eval_by_ttype(net, ctxt_fn, stim_fn, sample_fn, taskintL, ssizeL, n_ctxt_steps, neps):\n",
    "  \"\"\" eval on given task for separate trial types\n",
    "  returns evac on (match,nomatch,slure,clure)\n",
    "  \"\"\"\n",
    "\n",
    "  taskL_ev = []\n",
    "  # generate a list of tasks which are trials all of one kind so we can see accuracy by trial type\n",
    "  for task_int in taskintL:\n",
    "    taskL_ev.append([task_int, sample_fn(1, 0, 0), ssizeL[task_int]])\n",
    "    taskL_ev.append([task_int, sample_fn(0, 0, 0), ssizeL[task_int]])\n",
    "    taskL_ev.append([task_int, sample_fn(0, 1, 0), ssizeL[task_int]])\n",
    "    taskL_ev.append([task_int, sample_fn(0, 0, 1), ssizeL[task_int]])\n",
    "\n",
    "  evsc, ttype = run_model_for_epochs(\n",
    "    net, \n",
    "    taskL_ev,\n",
    "    ctxt_fn=ctxt_fn,\n",
    "    stim_fn = stim_fn,\n",
    "    training=False,\n",
    "    neps_per_task=neps,\n",
    "    n_ctxt_steps=n_ctxt_steps,\n",
    "    verb=False\n",
    "  )\n",
    "\n",
    "  evac = evsc.mean(1)\n",
    "  print(evac)\n",
    "  # regroup the list of scores into a list of lists grouped by the setsize\n",
    "  scores_by_ss = [[]] * len(taskintL)\n",
    "  for task_int in taskintL:\n",
    "    scores_by_ss[task_int] = evac[task_int*4:(task_int+1)*4]\n",
    "  return scores_by_ss\n",
    "\n",
    "# eval on neps_ev iterations of each trial type and plot the accuracy for each\n",
    "def plot_accuracy_by_trial_type(evac,\n",
    "                                taskintL,\n",
    "                                ssizeL,\n",
    "                                figure_path=\"\"):\n",
    "  for tidx, (task_int, ssize) in enumerate(zip(taskintL, ssizeL)):\n",
    "    plt.title('Accuracy by trial type')\n",
    "    plt.bar(np.arange(4) + (.45 * tidx), evac[tidx], width=.45, label=\"setsize:\" + str(ssize))\n",
    "  plt.legend()\n",
    "  plt.xticks(range(4), ['match', 'nomatch', 'slure', 'clure'])\n",
    "  # plt.savefig(figure_path + \"/trial-type-accuracy\")\n",
    "  # plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net_and_plot_accuracy(task, ctxt_fn, stim_fn, c_dim, s_dim, neps, n_ctxt_steps, pr_match, pr_slure, pr_clure, seed, model_path, figure_path):\n",
    "  np.random.seed(seed)\n",
    "  tr.random.manual_seed(seed)\n",
    "\n",
    "  ## net params\n",
    "  indim = 2 * (c_dim + s_dim)\n",
    "  hiddim = s_dim * 4\n",
    "\n",
    "  if task == 'nback':\n",
    "    ssizeL = [2, 3] # [1, 3]\n",
    "    sample_fn = lambda match,slure,clure: lambda S,C,N: single_nback_comparison(S,C,N,\n",
    "                  pr_match=match,pr_stim_lure=slure,pr_context_lure=clure\n",
    "                  )\n",
    "  elif task == 'stern':\n",
    "    ssizeL = [4,9]\n",
    "    sample_fn = lambda match,slure,clure: lambda S,C,N: single_sternberg_comparison(S,C,N,\n",
    "                  pr_match=match,pr_stim_lure=slure,pr_context_lure=clure\n",
    "                  )\n",
    "\n",
    "  taskintL = [0,1]\n",
    "  taskL_tr = [\n",
    "    [taskintL[0],sample_fn(pr_match,pr_slure,pr_clure),ssizeL[0]],\n",
    "    [taskintL[1],sample_fn(pr_match,pr_slure,pr_clure),ssizeL[1]],\n",
    "  ]\n",
    "\n",
    "  # init net\n",
    "  net = FFWM(indim,hiddim)\n",
    "\n",
    "  # train net\n",
    "  score_tr, ttype = run_model_for_epochs(\n",
    "    net,\n",
    "    taskL_tr,\n",
    "    ctxt_fn=ctxt_fn,\n",
    "    stim_fn = stim_fn,\n",
    "    training=True,\n",
    "    neps_per_task=neps,\n",
    "    n_ctxt_steps=n_ctxt_steps)\n",
    "\n",
    "  np.save(model_path + \"/train-score\", score_tr)\n",
    "  tr.save(net.state_dict(), model_path + \"/trained-net.pt\")\n",
    "\n",
    "  plot_train_accuracy(score_tr, ttype, ssizeL, figure_path)\n",
    "\n",
    "  scores_by_ttype = eval_by_ttype(net, ctxt_fn, stim_fn, sample_fn, taskintL, ssizeL, n_ctxt_steps, neps=1000)\n",
    "  plot_accuracy_by_trial_type(scores_by_ttype, taskintL, ssizeL, figure_path)\n",
    "\n",
    "  return net\n",
    "\n",
    "\n",
    "def generate_ttype_figures_for_trained_model(net, task, ctxt_fn, stim_fn, n_ctxt_steps): \n",
    "  if task == 'nback':\n",
    "    ssizeL = [2, 3]\n",
    "    sample_fn = lambda match,slure,clure: lambda S,C,N: single_nback_comparison(S,C,N,\n",
    "                  pr_match=match,pr_stim_lure=slure,pr_context_lure=clure\n",
    "                  )\n",
    "  elif task == 'stern':\n",
    "    ssizeL = [4,9]\n",
    "    sample_fn = lambda match,slure,clure: lambda S,C,N: single_sternberg_comparison(S,C,N,\n",
    "                  pr_match=match,pr_stim_lure=slure,pr_context_lure=clure\n",
    "                  )\n",
    "\n",
    "  taskintL = [0,1]\n",
    "  taskL_tr = [\n",
    "    [taskintL[0],sample_fn(pr_match,pr_slure,pr_clure),ssizeL[0]],\n",
    "    [taskintL[1],sample_fn(pr_match,pr_slure,pr_clure),ssizeL[1]],\n",
    "  ]\n",
    "    \n",
    "  scores_by_ttype = eval_by_ttype(net, ctxt_fn, stim_fn, sample_fn, taskintL, ssizeL, n_ctxt_steps, neps=1000)\n",
    "  plot_accuracy_by_trial_type(scores_by_ttype, taskintL, ssizeL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Parameters & Actually Train / Load a WM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating WM...\n",
      "[0.962 1.    0.892 1.    0.981 0.998 0.773 0.998]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# change this variable to change the task between nback and stern\n",
    "task = \"nback\"  # \"stern\"\n",
    "\n",
    "# function and parameters for the drifting context\n",
    "ctxt_fn_name = spherical_drift\n",
    "ctxt_d = 25\n",
    "n_ctxt_steps=20\n",
    "drift_parameters = (0.25, 0.075) # [(0.25, 0.075), (0.25, 0.0), (0.25, 0.05), (0.4, 0.075)]\n",
    "mean, var = drift_parameters\n",
    "# Lambda getter for the context fn with these parameters\n",
    "ctxt_fn = lambda n_steps: spherical_drift(n_steps=n_steps, dim=ctxt_d, var=var, mean=mean)\n",
    "\n",
    "# function which returns a stimulus\n",
    "stim_fn = lambda: gen_stims(stim_d) # lambda: gen_stims(stim_d)\n",
    "\n",
    "load_pretrained_model = True\n",
    "\n",
    "if load_pretrained_model: \n",
    "    model_path = \"/Users/maia/Projects/cleaned-em-wm-code/trained-models/ffwm_task-nback_training-probs-040-020-020-020_neps-500000_drift-params-025-007_seed%2/trained-net.pt\"\n",
    "    model = FFWM(2 * (ctxt_d + stim_d), stim_d * 4)\n",
    "    model.load_state_dict(tr.load(model_path))\n",
    "    model.eval()\n",
    "    generate_ttype_figures_for_trained_model(model, task, ctxt_fn, stim_fn, n_ctxt_steps=n_ctxt_steps)\n",
    "else: \n",
    "    # probabilities of different training conditions: both match, stimulus lure, context lure, neither match\n",
    "    pr_match, pr_slure, pr_clure, pr_nomatch = 0.4, 0.2, 0.2, 0.2\n",
    "    n_training_eps=500000\n",
    "    net = train_net_and_plot_accuracy(task, ctxt_fn, stim_fn, c_dim=ctxt_d, s_dim=stim_d, neps=n_training_eps, n_ctxt_steps=n_ctxt_steps,\n",
    "                                    pr_match=pr_match, pr_slure=pr_slure, pr_clure=pr_clure, seed=seed,\n",
    "                                    model_path=model_path, figure_path=figure_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cosine similarity between two vectors\n",
    "def cos_sim(a, b):\n",
    "    return cosine_similarity(a.reshape(1, -1), b.reshape(1, -1))\n",
    "\n",
    "# Simulate the sequence retrieved from EM based on the sequence types from Kane et. al.\n",
    "# (control/lure target/foil), returning a sequence made up of the stimuli in memory & a code indicating seque\n",
    "def sample_nback_retrieval_set_for_trial_sequence(stimset, cdrift, setsize,\n",
    "                                          pr_match, pr_stim_lure, pr_context_lure):\n",
    "    n_traces = 10\n",
    "    trace_seq = [None] * n_traces\n",
    "    ntokens,sdim = stimset.shape\n",
    "    min_context_t = setsize\n",
    "\n",
    "    ## current stim and context\n",
    "    stim_t_idx = np.random.randint(0,ntokens)\n",
    "    context_t_idx = np.random.randint(min_context_t, ntokens)\n",
    "    stim_t = stimset[stim_t_idx]\n",
    "    context_t = cdrift[context_t_idx]\n",
    "    trace_seq[0] = (stim_t, context_t) # the 0th index is the current stim, context\n",
    "\n",
    "    ttype_rand_n = np.random.random() # random number for determining the trial type\n",
    "    ttype_code = -1  # code for the trial type that will be returned - 0 if a control, and 1 if a lure\n",
    "\n",
    "    # control target\n",
    "    if ttype_rand_n < pr_match:\n",
    "        # One trace in the n-back position with a matching stimulus\n",
    "        trace_seq[setsize] = nback_both_match(stimset, cdrift, stim_t_idx, context_t_idx, setsize, ntokens)\n",
    "        # All other traces in the sequence are from non-nback positions and have non-matching stimuli\n",
    "        for i in range(1, n_traces):\n",
    "          if i != setsize:\n",
    "              trace_seq[i] = nback_neither_match(stimset, cdrift, stim_t_idx, context_t_idx, setsize, ntokens)\n",
    "        ytarget = tr.LongTensor([1])\n",
    "        ttype_code = 0\n",
    "\n",
    "    # control foil\n",
    "    elif ttype_rand_n < (pr_match + pr_context_lure):\n",
    "        # One trace in the n-back position with a non-matching stimulus\n",
    "        trace_seq[setsize] = nback_ctxt_lure(stimset, cdrift, stim_t_idx, context_t_idx, setsize, ntokens)\n",
    "        # All other traces in the sequence have non-matching stimuli\n",
    "        for i in range(1, n_traces):\n",
    "            if i != setsize:\n",
    "                trace_seq[i] = nback_neither_match(stimset, cdrift, stim_t_idx, context_t_idx, setsize, ntokens)\n",
    "        ytarget = tr.LongTensor([0])\n",
    "        ttype_code = 0\n",
    "\n",
    "    # lure target\n",
    "    elif ttype_rand_n < (pr_match + pr_context_lure + pr_stim_lure):\n",
    "        # One trace in the n-back position with a matching stimulus\n",
    "        trace_seq[setsize] = nback_both_match(stimset, cdrift, stim_t_idx, context_t_idx, setsize, ntokens)\n",
    "        # One trace in the non n-back position has a non-matching stimulus\n",
    "        trace_seq[setsize - 1] = nback_stim_lure(stimset, cdrift, stim_t_idx, context_t_idx, setsize, ntokens)\n",
    "        # All other traces have non-matching stimuli\n",
    "        for i in range(1, n_traces):\n",
    "            if i != setsize and i != setsize - 1:\n",
    "                trace_seq[i] = nback_neither_match(stimset, cdrift, stim_t_idx, context_t_idx, setsize, ntokens)\n",
    "        ytarget = tr.LongTensor([1])\n",
    "        ttype_code = 1\n",
    "\n",
    "    # lure foil\n",
    "    else:\n",
    "      # The trace in the n-back position has a non-matching stimulus\n",
    "      trace_seq[1] = nback_ctxt_lure(stimset, cdrift, stim_t_idx, context_t_idx, setsize, ntokens)\n",
    "      # The trace one-after the n-back position (the lure position) has a matching stimulus\n",
    "      trace_seq[2] = nback_stim_lure(stimset, cdrift, stim_t_idx, context_t_idx, setsize, ntokens)\n",
    "      # All other traces in the sequence other than the n-back position have non-matching stimuli\n",
    "      for i in range(3, n_traces):\n",
    "        trace_seq[i] = nback_neither_match(stimset, cdrift, stim_t_idx, context_t_idx, setsize, ntokens)\n",
    "      ytarget = tr.LongTensor([0])\n",
    "      ttype_code = 1\n",
    "\n",
    "    return trace_seq, ytarget, ttype_code\n",
    "\n",
    "# Evaluate the EM model to get its accuracy score for different kinds of nback sequences\n",
    "def get_em_model_performance(net, taskL, ctxt_fn, stim_fn, neps_per_task, n_context_steps, stim_priority_weight, hrate, sim_thresh):\n",
    "    net.eval()\n",
    "    score = -np.ones([len(taskL), neps_per_task, 2]) # array of performance information\n",
    "    ttype = -np.ones([len(taskL), neps_per_task]) # array of trial-type information for d' measures\n",
    "    for ep in range(neps_per_task):\n",
    "        # resample context for this epoch\n",
    "        stimset = tr.Tensor(stim_fn())\n",
    "        cdrift = ctxt_fn(n_steps=n_context_steps)\n",
    "        cdrift = tr.Tensor(cdrift)\n",
    "        # interleave training for multiple task conditions each epoch\n",
    "        for task_idx,(control_int,sample_trial_fn,setsize) in enumerate(taskL):\n",
    "          # generate sample trace set\n",
    "          stimseq,ytarget, ttype_idx = sample_trial_fn(stimset,cdrift,setsize)\n",
    "          target = stimseq[0]\n",
    "          sim_scores = []\n",
    "          for memory in stimseq[1:]:\n",
    "              # calculate a trace's retrieval priority based on weighted cosine similarity between the trace and the current trace\n",
    "              cs_stim = cos_sim(target[0], memory[0])\n",
    "              cs_ctxt = cos_sim(target[1], memory[1])\n",
    "              sim = stim_priority_weight * cs_stim + (1 - stim_priority_weight) * cs_ctxt # weighting parameter\n",
    "              sim_scores.append(sim)\n",
    "          pred = 0\n",
    "          # repeat as long as there are traces in the retrieval set\n",
    "          for i in range(len(sim_scores)):\n",
    "              max_sim_idx = np.argmax(np.array(sim_scores)) # pick the remaining trace with the highest similarity\n",
    "              if (sim_scores[max_sim_idx] < sim_thresh):\n",
    "                  break # break if the most-similar trace is under the threshold\n",
    "              memory = stimseq[max_sim_idx + 1]\n",
    "              inputL = [target[0],memory[0],target[1],memory[1]]\n",
    "              yhat = net(inputL,control_bias_int=control_int)\n",
    "              # predict a label for the trace\n",
    "              pred = maxsoftmax(yhat).item()\n",
    "              if pred == 1: # stop search if the model identifies a trace that evidences a positive trial\n",
    "                  break\n",
    "              if np.random.uniform() > (hrate): # stop search with probability hrate\n",
    "                  break\n",
    "              else:\n",
    "                  sim_scores[max_sim_idx] = 0 # else zero out the retrieval priority of this trace\n",
    "          score[task_idx, ep, 0] = pred\n",
    "          score[task_idx, ep, 1] = ytarget.item()\n",
    "          ttype[task_idx, ep] = ttype_idx\n",
    "    return score, ttype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot d' Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate d' based on hit rate and false alarm rate as in Kane et al\n",
    "def paper_dprime(hrate, farate):\n",
    "    hrate = clamp(hrate, 0.01, 0.99)\n",
    "    farate = clamp(farate, 0.01, 0.99)\n",
    "    dl = np.log(hrate * (1 - farate) / ((1 - hrate) * farate))\n",
    "    c = 0.5 * np.log((1 - hrate) * (1 - farate) / (hrate * farate))\n",
    "    return dl, c\n",
    "\n",
    "\n",
    "# calculate d' measures for a set of accuracy scores and plot the result\n",
    "def calculate_and_plot_dprime(evsc, ttype, dprime_figure_path):\n",
    "    taskL = [0, 1]\n",
    "    rate_sum = np.zeros([len(taskL), 2, 4])\n",
    "\n",
    "    dprimes = [None] * 4\n",
    "    bias = [None] * 4\n",
    "    hits = [None] * 4\n",
    "    correct_rejections = [None] * 4\n",
    "    labels = [\"2-back ctrl\", \"2-back lure\", \"3-back ctrl\", \"3-back lure\"]\n",
    "\n",
    "    idx = 0\n",
    "\n",
    "    for task in taskL:\n",
    "        task_score = evsc[task]\n",
    "        for i in range(len(task_score)):\n",
    "            ep = task_score[i]\n",
    "            ttype_idx = int(ttype[task, i])\n",
    "            if ep[0] == 1 and ep[1] == 1:\n",
    "                rate_sum[task, ttype_idx, 0] += 1\n",
    "            elif ep[0] == 1 and ep[1] == 0:\n",
    "                rate_sum[task, ttype_idx, 1] += 1\n",
    "            elif ep[0] == 0 and ep[1] == 1:\n",
    "                rate_sum[task, ttype_idx, 2] += 1\n",
    "            elif ep[0] == 0 and ep[1] == 0:\n",
    "                rate_sum[task, ttype_idx, 3] += 1\n",
    "            else:\n",
    "                raise ValueError(\"unexpected set of values: \" + str(ep))\n",
    "        for ttype_idx in [0, 1]:\n",
    "            n_ytrials = rate_sum[task, ttype_idx, 0] + rate_sum[task, ttype_idx, 2]\n",
    "            n_ntrials = rate_sum[task, ttype_idx, 1] + rate_sum[task, ttype_idx, 3]\n",
    "            rate_sum[task, ttype_idx, 0] = rate_sum[task, ttype_idx, 0] / n_ytrials\n",
    "            rate_sum[task, ttype_idx, 1] = rate_sum[task, ttype_idx, 1] / n_ntrials\n",
    "            rate_sum[task, ttype_idx, 2] = rate_sum[task, ttype_idx, 2] / n_ytrials\n",
    "            rate_sum[task, ttype_idx, 3] = rate_sum[task, ttype_idx, 3] / n_ntrials\n",
    "            dprime, sensitivity = paper_dprime(rate_sum[task, ttype_idx][0], rate_sum[task, ttype_idx][1])\n",
    "            dprimes[idx] = dprime\n",
    "            bias[idx] = sensitivity\n",
    "            hits[idx] = rate_sum[task, ttype_idx, 0]\n",
    "            correct_rejections[idx] = rate_sum[task, ttype_idx, 3]\n",
    "            idx += 1\n",
    "\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(10, 15))\n",
    "    width = 0.9\n",
    "\n",
    "    fig.suptitle(\"d-prime measures of retrieval model performance\", fontsize=20)\n",
    "\n",
    "    titles = [\"correct rejections\", \"hits\", \"sensitivity\", \"bias\"]\n",
    "    stats = [correct_rejections, hits, dprimes, bias]\n",
    "    colors = [\"C0\", to_rgba(\"C0\", 0.7), \"C1\", to_rgba(\"C1\", 0.7)]\n",
    "\n",
    "    for i in range(4):\n",
    "        ax = axs[int(i / 2), i%2]\n",
    "        for j in range(4):\n",
    "            ax.bar(j, stats[i][j], width, label=labels[j], color=colors[j])\n",
    "        ax.tick_params(axis='x', which=\"both\", bottom=False)\n",
    "        ax.set_title(titles[i], y=-0.12)\n",
    "        if i < 2:\n",
    "            ax.set_ylim(0, 1.1)\n",
    "        else:\n",
    "            ax.set_ylim(-5, 10)\n",
    "            ax.axhline(0, color=\"black\")\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(\"Correct Rejection / Hit Rate\")\n",
    "        if i == 2:\n",
    "            ax.set_ylabel(\"Signal Detection Measures\")\n",
    "        if i == 3:\n",
    "            ax.legend()\n",
    "\n",
    "    # plt.savefig(dprime_figure_path)\n",
    "    # plt.close('all')\n",
    "    \n",
    "# generate accuracy scores for sequences in EM and use the scores to plot d'    \n",
    "def simulate_em_and_plot_dprimes(net, ctxt_fn, stim_fn, neps_per_task, pr_match, pr_slure, pr_clure, n_context_steps, stim_priority_weight, hrate, sim_thresh, figure_path=\"\"):\n",
    "    ssizeL = [2, 3]\n",
    "    sample_fn = lambda match, slure, clure: lambda S, C, N: sample_nback_retrieval_set_for_trial_sequence(S, C, N,\n",
    "                                                                                    pr_match=match,\n",
    "                                                                                    pr_stim_lure=slure,\n",
    "                                                                                    pr_context_lure=clure\n",
    "                                                                                    )\n",
    "    taskintL = [0, 1]\n",
    "    taskL = [\n",
    "        [taskintL[0], sample_fn(pr_match, pr_slure, pr_clure), ssizeL[0]],\n",
    "        [taskintL[1], sample_fn(pr_match, pr_slure, pr_clure), ssizeL[1]],\n",
    "    ]\n",
    "\n",
    "    score, ttype = get_em_model_performance(net, taskL, ctxt_fn, stim_fn, neps_per_task, n_context_steps,\n",
    "                                            stim_priority_weight, hrate, sim_thresh)\n",
    "\n",
    "    dprime_fig_path = figure_path + (\"/dprime\" + '_sw=' + str(stim_priority_weight) + \"_hrate=\" + str(hrate)).replace(\".\", \"\")\n",
    "\n",
    "    calculate_and_plot_dprime(score, ttype, dprime_figure_path=dprime_fig_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the model to generate EM figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating EM...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'clamp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-e54c511d64e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                \u001b[0mhrate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                                \u001b[0msim_thresh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilarity_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                               figure_path=\"\")\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-7bb30c5eb7d2>\u001b[0m in \u001b[0;36msimulate_em_and_plot_dprimes\u001b[0;34m(net, ctxt_fn, stim_fn, neps_per_task, pr_match, pr_slure, pr_clure, n_context_steps, stim_priority_weight, hrate, sim_thresh, figure_path)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mdprime_fig_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfigure_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"/dprime\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_sw='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstim_priority_weight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_hrate=\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0mcalculate_and_plot_dprime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mttype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdprime_figure_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdprime_fig_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-7bb30c5eb7d2>\u001b[0m in \u001b[0;36mcalculate_and_plot_dprime\u001b[0;34m(evsc, ttype, dprime_figure_path)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mrate_sum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mttype_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrate_sum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mttype_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_ytrials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mrate_sum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mttype_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrate_sum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mttype_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_ntrials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mdprime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensitivity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaper_dprime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrate_sum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mttype_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate_sum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mttype_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mdprimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdprime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mbias\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msensitivity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-7bb30c5eb7d2>\u001b[0m in \u001b[0;36mpaper_dprime\u001b[0;34m(hrate, farate)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# calculate d' based on hit rate and false alarm rate as in Kane et al\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpaper_dprime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfarate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mhrate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mfarate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfarate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhrate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfarate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mhrate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfarate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clamp' is not defined"
     ]
    }
   ],
   "source": [
    "# priority weighting of stimulus similarity (vs context similarity) in EM retrieval\n",
    "stim_retrieval_weight = 0.4\n",
    "# hazard rate - likelihood of terminating memory search at each step\n",
    "h_rate = 0.6\n",
    "# similarity threshold cutoff - min cosine similarity before search is terminated deterministically\n",
    "similarity_threshold = 0.5\n",
    "\n",
    "if task == \"nback\":\n",
    "  print(\"Simulating EM...\")\n",
    "  simulate_em_and_plot_dprimes(model, ctxt_fn, stim_fn,\n",
    "                               neps_per_task=1000, pr_match=pr_match,\n",
    "                                pr_slure=pr_slure, pr_clure=pr_clure, n_context_steps=n_ctxt_steps,\n",
    "                               stim_priority_weight=stim_retrieval_weight,\n",
    "                               hrate = h_rate,\n",
    "                               sim_thresh = similarity_threshold,\n",
    "                              figure_path=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
