{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'brownian'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a2d83bedb7e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/maia/Projects/thesis-code/drift_fn_models\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# from brownian_manifold.manifold import Manifold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbrownian\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbrownian\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfft\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mifft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfftshift\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'brownian'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import sys\n",
    "sys.path.append(\"/Users/maia/Projects/brownian-manifold/\")\n",
    "sys.path.append(\"/Users/maia/Projects/thesis-code/drift_fn_models\")\n",
    "# from brownian_manifold.manifold import Manifold\n",
    "from brownian import brownian\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from numpy.fft import fft, ifft, fftshift\n",
    "import scipy\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(a, b): \n",
    "#     return np.dot(a, b) / (np.sqrt(np.dot(a,a)) * np.sqrt(np.dot(b, b)))\n",
    "    return cosine_similarity(a.reshape(1, -1), b.reshape(1, -1))\n",
    "\n",
    "def estimate_step_similarity_over_time(steps, d_intervals, n_samples=100, euclidean=False):\n",
    "    indices = list(range(len(steps) - d_intervals[-1]))\n",
    "    interval_indices = list(range(len(d_intervals)))\n",
    "    avg_d = np.zeros(len(d_intervals))\n",
    "    min_d = np.zeros(len(d_intervals)) - 1\n",
    "    max_d = np.zeros(len(d_intervals)) - 1\n",
    "    vals = np.zeros((n_samples, len(d_intervals)))\n",
    "    for i in range(n_samples):\n",
    "        start_ind = np.random.choice(indices)\n",
    "\n",
    "        for j in interval_indices:\n",
    "            if euclidean: \n",
    "                d = np.linalg.norm(steps[start_ind] - steps[start_ind + d_intervals[j]])\n",
    "            else: \n",
    "                d = cos_sim(steps[start_ind], steps[start_ind + d_intervals[j]])\n",
    "            vals[i, j] = d\n",
    "    #             avg_d[j] += d\n",
    "    #             if d < min_d[j] or min_d[j] == -1:\n",
    "    #                 min_d[j] = d\n",
    "    #             if d > max_d[j] or max_d[j] == -1:\n",
    "    #                 max_d[j] = d\n",
    "    # return avg_d / n_samples, min_d, max_d\n",
    "    avg = np.mean(vals, axis=0)\n",
    "    stddev = np.std(vals, axis=0)\n",
    "    mind = np.min(vals, axis=0)\n",
    "    maxd = np.max(vals, axis=0)\n",
    "    return avg, stddev, mind, maxd\n",
    "\n",
    "def single_series_time_average(steps, d_intervals, euclidean=False, centered=False):\n",
    "    indices = list(range(len(steps) - d_intervals[-1]))\n",
    "    interval_indices = list(range(len(d_intervals)))\n",
    "    vals = np.zeros((len(indices), len(d_intervals)))\n",
    "    for k in indices:\n",
    "        for j in interval_indices:\n",
    "            if euclidean: \n",
    "                v = np.linalg.norm(steps[k] - steps[k + d_intervals[j]])\n",
    "            else: \n",
    "                if centered and k > 0: \n",
    "                    origin_offset = steps[k - 1]\n",
    "                else: \n",
    "                    origin_offset = 0\n",
    "                reference_pt = steps[k] - origin_offset\n",
    "                comparison_pt = steps[k + d_intervals[j]] - origin_offset\n",
    "                v = cos_sim(reference_pt, comparison_pt)\n",
    "            vals[k, j] = v\n",
    "#     print(np.max(vals[1:50], axis=0))\n",
    "#     print(np.max(vals[50:100], axis=0))\n",
    "#     print(np.min(vals[1:50], axis=0))\n",
    "#     print(np.min(vals[50:100], axis=0))\n",
    "    avg = np.mean(vals[1:], axis=0)\n",
    "    stddev = np.std(vals[1:], axis=0)\n",
    "    return avg, stddev\n",
    "\n",
    "def single_series_time_average_from_start(steps, d_intervals, start_pt=0, euclidean=False, centered=False):\n",
    "    interval_indices = list(range(100))\n",
    "    vals = np.zeros(len(interval_indices))\n",
    "    k = start_pt \n",
    "    for j in interval_indices:\n",
    "        if euclidean: \n",
    "            v = np.linalg.norm(steps[k] - steps[k + interval_indices[j]])\n",
    "        else: \n",
    "            if centered and k > 0: \n",
    "                origin_offset = steps[k - 1]\n",
    "            else: \n",
    "                origin_offset = 0\n",
    "            reference_pt = steps[k] - origin_offset\n",
    "            comparison_pt = steps[k + interval_indices[j]] - origin_offset\n",
    "            v = cos_sim(reference_pt, comparison_pt)\n",
    "        vals[j] = v\n",
    "    return vals, np.zeros(vals.shape)\n",
    "\n",
    "def multi_series_time_average(context_fun, d_intervals, n_samples, euclidean=False):\n",
    "    vals = np.zeros((n_samples, len(d_intervals)))\n",
    "    avg_avg = 0\n",
    "    avg_stddev = 0\n",
    "    for i in range(n_samples):\n",
    "        context = context_fun()\n",
    "        avg, stddev = centered_single_series_time_average(context, d_intervals, euclidean) # single_series_time_average(context, d_intervals, euclidean)\n",
    "    return avg, stddev, mind, maxd\n",
    "\n",
    "def bucketed_avg_similarity(steps, d_intervals, n_samples=100, euclidean=False):\n",
    "    indices = list(range(len(steps) - d_intervals[-1]))\n",
    "    interval_indices = list(range(len(d_intervals)))\n",
    "    avg_d = np.zeros(len(d_intervals))\n",
    "    min_d = np.zeros(len(d_intervals)) - 1\n",
    "    max_d = np.zeros(len(d_intervals)) - 1\n",
    "    vals = np.zeros((n_samples, len(d_intervals)))\n",
    "    for i in range(n_samples):\n",
    "        start_ind = np.random.choice(indices)\n",
    "\n",
    "        for j in interval_indices:\n",
    "            if euclidean: \n",
    "                d = np.linalg.norm(steps[start_ind] - steps[start_ind + d_intervals[j]])\n",
    "            else: \n",
    "                d = cos_sim(steps[start_ind], steps[start_ind + d_intervals[j]])\n",
    "            vals[i, j] = d\n",
    "    #             avg_d[j] += d\n",
    "    #             if d < min_d[j] or min_d[j] == -1:\n",
    "    #                 min_d[j] = d\n",
    "    #             if d > max_d[j] or max_d[j] == -1:\n",
    "    #                 max_d[j] = d\n",
    "    # return avg_d / n_samples, min_d, max_d\n",
    "    avg = np.mean(vals, axis=0)\n",
    "    stddev = np.std(vals, axis=0)\n",
    "    mind = np.min(vals, axis=0)\n",
    "    maxd = np.max(vals, axis=0)\n",
    "    return avg, stddev, mind, maxd\n",
    "    \n",
    "\n",
    "def autocorrelation_of_intervals(steps, d_intervals, n_samples=100, euclidean=False):\n",
    "    indices = list(range(len(steps) - d_intervals[-1]))\n",
    "    interval_indices = list(range(len(d_intervals)))\n",
    "    avg_d = np.zeros(len(d_intervals))\n",
    "    min_d = np.zeros(len(d_intervals)) - 1\n",
    "    max_d = np.zeros(len(d_intervals)) - 1\n",
    "    vals = np.zeros((n_samples, len(d_intervals)))\n",
    "    min_end = len(steps) - d_intervals[-1]\n",
    "    for j in interval_indices:\n",
    "        int_end = min_end + d_intervals[j]\n",
    "        d_intervals[j]\n",
    "        d = autocorr(steps[:int_end], d_intervals[j])\n",
    "        # vals[:, j] = d\n",
    "    avg = np.mean(vals, axis=0)\n",
    "    stddev = np.std(vals, axis=0)\n",
    "    mind = np.min(vals, axis=0)\n",
    "    maxd = np.max(vals, axis=0)\n",
    "    return avg, stddev, mind, maxd\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def iid_noise(n_steps=20, dim=10, var=0.0, mean=1, beta=0.0, multi_steps=0):\n",
    "    ctxt = np.zeros((n_steps, dim))\n",
    "    ctxt[0] = np.random.random(dim)\n",
    "    for i in range(1, n_steps):\n",
    "        noise = np.random.normal(mean, var, size=dim)\n",
    "        ctxt[i] = ctxt[i - 1] + noise\n",
    "    if mean == 0:\n",
    "        stem = \"walk_diffusion_\"\n",
    "    else:\n",
    "        stem = \"walk_drift_\"\n",
    "    fn_name = stem + \"d=\" + str(dim) + \"_m=\" + str(mean) + \"_v=\" + str(var)\n",
    "    return ctxt, fn_name\n",
    "\n",
    "\n",
    "def path_integration(n_steps=10, var=0.3, mean=0.0, dim=10, beta=0.3, multi_steps=1, normed=False):\n",
    "    ctxt = np.zeros((n_steps, dim))\n",
    "    #ctxt[0] = np.random.random(dim) * var + mean\n",
    "    for i in range(1, n_steps):\n",
    "        prev_c = ctxt[i - 1]\n",
    "        for j in range(multi_steps):\n",
    "            stim = np.random.normal(mean, var, size=(dim))\n",
    "            stim = np.expand_dims(stim, axis=0)\n",
    "            prev_c = (1 - beta) * prev_c + beta * stim\n",
    "            # print(np.linalg.norm(prev_c))\n",
    "            if normed:\n",
    "                prev_c = prev_c / np.linalg.norm(prev_c)\n",
    "        ctxt[i] = prev_c\n",
    "    if mean == 0:\n",
    "        stem = \"path_integration_diffusion_\"\n",
    "    else:\n",
    "        stem = \"path_integration_drift_\"\n",
    "    fn_name = stem + \"d=\" + str(dim) + \"_m=\" + str(mean) + \"_v=\" + str(var) + \"_b=\" + str(beta)\n",
    "    return ctxt, fn_name\n",
    "\n",
    "def n_sphere(n_steps=20, dim=10, var=0.25, mean=0.25, beta=0.0):\n",
    "    ros = np.random.random(dim - 1)\n",
    "    # ros = np.zeros(dim - 1)\n",
    "    slen = n_steps\n",
    "    ctxt = np.zeros((slen, dim))\n",
    "    for i in range(slen):\n",
    "        noise = np.random.normal(mean, var, size=(dim - 1))\n",
    "        # print(noise)\n",
    "        ros += noise\n",
    "        ct = np.zeros(dim)\n",
    "        ct[0] = np.cos(ros[0])\n",
    "        for j in range(dim - 2):\n",
    "            amt = np.product([np.sin(ros[k]) for k in range(j + 1)])\n",
    "            amt *= np.cos(ros[j + 1])\n",
    "            ct[j + 1] = amt\n",
    "        ct[dim - 1] = np.product([np.sin(ros[j]) for j in range(dim - 1)])\n",
    "        ctxt[i] = ct\n",
    "    if mean == 0:\n",
    "        stem = \"spherical_diffusion_\"\n",
    "    else:\n",
    "        stem = \"spherical_drift_\"\n",
    "    fn_name = stem + \"d=\" + str(dim) + \"_m=\" + str(mean) + \"_v=\" + str(var)\n",
    "    return ctxt, fn_name\n",
    "\n",
    "def fast_n_sphere(n_steps=20, dim=10, var=0.25, mean=0.25, beta=0.0):\n",
    "    ros = np.zeros(dim - 1)\n",
    "    slen = n_steps\n",
    "    ctxt = np.zeros((slen, dim))\n",
    "    for i in range(slen):\n",
    "        noise = np.random.normal(mean, var, size=(dim - 1))\n",
    "        ros += noise\n",
    "        ct = np.zeros(dim)\n",
    "        prod = 1\n",
    "        for j in range(dim - 1):\n",
    "            amt = prod * np.cos(ros[j])\n",
    "            ct[j] = amt\n",
    "            prod *= np.sin(ros[j])\n",
    "        ct[dim - 1] = prod\n",
    "        ctxt[i] = ct\n",
    "    if mean == 0:\n",
    "        stem = \"fast_spherical_diffusion_\"\n",
    "    else:\n",
    "        stem = \"fast_spherical_drift_\"\n",
    "    fn_name = stem + \"d=\" + str(dim) + \"_m=\" + str(mean) + \"_v=\" + str(var)\n",
    "    return ctxt, fn_name\n",
    "\n",
    "def new_n_sphere(n_steps=20, dim=10, var=0.25, mean=0.25, beta=0.0):\n",
    "    ros = np.zeros(dim - 1)\n",
    "    slen = n_steps\n",
    "    ctxt = np.zeros((slen, dim))\n",
    "    for i in range(slen):\n",
    "        noise = np.random.normal(mean, var, size=(dim - 1))\n",
    "        ros += noise\n",
    "        ct = np.zeros(dim)\n",
    "        ct[0] = np.cos(ros[0])\n",
    "        prod = np.product([np.sin(ros[k]) for k in range(1, dim - 1)])\n",
    "        n_prod = prod\n",
    "        for j in range(dim - 2):\n",
    "            n_prod /= np.sin(ros[j + 1])\n",
    "            amt = n_prod * np.cos(ros[j + 1])\n",
    "            ct[j + 1] = amt\n",
    "        ct[dim - 1] = prod\n",
    "        ctxt[i] = ct\n",
    "    if mean == 0:\n",
    "        stem = \"new_spherical_diffusion_\"\n",
    "    else:\n",
    "        stem = \"new_spherical_drift_\"\n",
    "    fn_name = stem + \"d=\" + str(dim) + \"_m=\" + str(mean) + \"_v=\" + str(var)\n",
    "    return ctxt, fn_name\n",
    "\n",
    "\n",
    "def new_multiscale_n_sphere(n_steps=20, dim=10, var=0.25, mean=0.25, beta=0.0):\n",
    "    ros = np.zeros(dim - 1)\n",
    "    slen = n_steps\n",
    "    ctxt = np.zeros((slen, dim))\n",
    "    ms = np.linspace(0, mean, num=dim)\n",
    "    ms = ms[1:]\n",
    "    vs = np.zeros(dim - 1)\n",
    "    for i in range(slen):\n",
    "        noise = np.random.normal(ms, vs, size=(dim - 1))\n",
    "        ros += noise\n",
    "        ct = np.zeros(dim)\n",
    "        ct[0] = np.cos(ros[0])\n",
    "        prod = np.product([np.sin(ros[k]) for k in range(1, dim - 1)])\n",
    "        n_prod = prod\n",
    "        for j in range(dim - 2):\n",
    "            n_prod /= np.sin(ros[j + 1])\n",
    "            amt = n_prod * np.cos(ros[j + 1])\n",
    "            ct[j + 1] = amt\n",
    "        ct[dim - 1] = prod\n",
    "        ctxt[i] = ct\n",
    "    if mean == 0:\n",
    "        stem = \"new_multiscale_spherical_diffusion_\"\n",
    "    else:\n",
    "        stem = \"new_multiscale_spherical_drift_\"\n",
    "    fn_name = stem + \"d=\" + str(dim) + \"_m=\" + str(mean) + \"_v=\" + str(var)\n",
    "    return ctxt, fn_name\n",
    "\n",
    "def multiscale_n_sphere(n_steps=20, dim=10, var=0.25, mean=0.25, beta=0.0):\n",
    "    ros = np.zeros(dim - 1)\n",
    "    # ros = np.zeros(dim - 1)\n",
    "    slen = n_steps\n",
    "    ctxt = np.zeros((slen, dim))\n",
    "    ms = np.linspace(0, mean, num=dim)\n",
    "    ms = ms[1:]\n",
    "    # should this be 0 variance? Or variance that increases along w mean of dimension?\n",
    "    vs = np.zeros(dim - 1)\n",
    "    for i in range(slen):\n",
    "        noise = np.random.normal(ms, vs, size=(dim - 1))\n",
    "        ros += noise\n",
    "        ct = np.zeros(dim)\n",
    "        prod = 1\n",
    "        for j in range(dim - 1):\n",
    "            amt = prod * np.cos(ros[j])\n",
    "            ct[j] = amt\n",
    "            prod *= np.sin(ros[j])\n",
    "        ct[dim - 1] = prod\n",
    "        ctxt[i] = ct\n",
    "    if mean == 0:\n",
    "        stem = \"multiscale_spherical_diffusion_\"\n",
    "    else:\n",
    "        stem = \"multiscale_spherical_drift_\"\n",
    "    fn_name = stem + \"d=\" + str(dim) + \"_m=\" + str(mean) + \"_v=\" + str(var)\n",
    "    return ctxt, fn_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean = False\n",
    "short_int = True\n",
    "if short_int: \n",
    "    d_intervals = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "else: \n",
    "    d_intervals = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "    d_intervals = list(range(100))\n",
    "prefix = \"Autocorr using euclidean dist b/t intervals, dim=\" if euclidean else \"Autocorr using cosine similarity, \"\n",
    "n_samples=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_fn = fast_n_sphere\n",
    "\n",
    "##### stim_d = 100\n",
    "var = 0.05\n",
    "mean = 0.25\n",
    "beta = 0.0\n",
    "multi_step = 1\n",
    "dim = 25\n",
    "start_pt = 0\n",
    "\n",
    "ctxt, fn_name = context_fn(n_steps=10, var=var, mean=mean, dim=dim, beta=beta)\n",
    "\n",
    "param_title_string = \"autocorrelation, \" + fn_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# CHANGE BACK TO 5000\n",
    "steps = context_fn(n_steps=1000, var=var, mean=mean, dim=dim, beta=beta)[0]\n",
    "# avg_d, std_d = single_series_time_average_from_start(steps, d_intervals, start_pt=start_pt, euclidean=euclidean, centered=True)\n",
    "avg_d, std_d = single_series_time_average(steps, d_intervals, euclidean=euclidean, centered=True)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title(param_title_string)\n",
    "ax.errorbar(d_intervals, avg_d, yerr=std_d, color=\"red\")\n",
    "# ax.plot(d_intervals, min_d, color=\"blue\", label=\"min distance\")\n",
    "# ax.plot(d_intervals, max_d, color=\"green\", label=\"max distance\")\n",
    "ax.set_ylim(-0.25, 1.0)\n",
    "# ax.set_xscale(\"log\")\n",
    "fig.savefig(\"/Users/maia/Projects/thesis-code/Figures/autocorrelations/\" + fn_name + \"eudc=\" + str(euclidean) + \"_sint=\" + str(short_int) + \".png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "vis_title = fn_name\n",
    "ax.set_title(\"Drift on a 25-sphere\")\n",
    "for i in range(5):\n",
    "    ctxt = context_fn(n_steps=20, var=var, mean=mean, dim=25, beta=beta)[0]\n",
    "    ax.scatter(ctxt[1:, 0], ctxt[1:, 1], ctxt[1:, 2])\n",
    "    ax.plot(ctxt[1:, 0], ctxt[1:, 1], ctxt[1:, 2])\n",
    "fig.savefig(\"/Users/maia/Projects/thesis-code/Figures/posterfigs/25-\" + fn_name + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
